{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdUcQ4wITZxlzPE8Z/B8yY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AleemRahil/AI-DS/blob/main/MacroFinance_Model_InProgress.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9LB-A-nLfNN"
      },
      "outputs": [],
      "source": [
        ", tanh\n",
        "import sys\n",
        "sys.path.insert(0, '../')\n",
        "from scipy.optimize import fsolve\n",
        "from pylab import plt\n",
        "plt.style.use('seaborn')\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['font.family'] = 'serif'\n",
        "mpl.rcParams.update({'font.size': 15})\n",
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import cm\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import random\n",
        "from matplotlib import pyplot\n",
        "plt.rcParams['figure.facecolor'] = 'white'\n",
        "plt.rcParams['axes.grid'] = False\n",
        "plt.rcParams['grid.linewidth'] = 0\n",
        "import dill\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import glob\n",
        "import os.path\n",
        "import argparse\n",
        "from scipy.stats import norm\n",
        "from scipy.stats import t\n",
        "from tensorflow import keras\n",
        "import warnings\n",
        "warnings.filterwarnings('igmore')\n",
        "from keras.backend.set_floatx('float64')\n",
        "from tensorflow.keras.models import label_model\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Solve the 2D model')\n",
        "parser.add_argument('-s', '--save', type=bool, metavar='', nargs='?', default=True,\n",
        "                    help='Specify whether to save pickle (warning: requires ~1GB space)')\n",
        "parser.add_argument('-epochs', '--numEpochs', type=int, nargs='?', default=5000, help='Specify number of epochs')\n",
        "parser.add_argument('-bs', '--batchSize', type=int, nargs='?', default=2000, help='Specify batch size')\n",
        "parser.add_argument('-hidden', '--numLayers', type=int, nargs='?', default=5, help='Specify number of layers')\n",
        "parser.add_argument('-neurons', '--numNeurons', type=int, nargs='?', default=30, help='Specify number of neurons per layer')\n",
        "parser.add_argument('-maxIter', '--maxIterations', type=int, nargs='?', default=70, help='Specify number of iterations to run')\n",
        "args, unknown = parser.parse_known_args()\n",
        "\n",
        "class nnpde_informed_B1():\n",
        "  def __init__(self, linearTermE, advection_z_e, diffusion_z, J0_e, z, num_layers, batchSize, lr, adam_iter, dt,\n",
        "               linearTermH, advection_z_h, J0_h, params, X, X_pde) -> None:\n",
        "    self.linearTermE = linearTermE\n",
        "    self.advection_z_e = advection_z_e\n",
        "    self.diffusion_z = diffusion_z\n",
        "    self.linearTermH = linearTermH\n",
        "    self.advection_z_h = advection_z_h\n",
        "    self.J0_e = J0_e\n",
        "    self.J0_h = J0_h\n",
        "    self.z, self.dt = z, dt\n",
        "    self.num_layers = num_layers\n",
        "    self.lr = lr\n",
        "    self.adam.iter = adam_iter\n",
        "    self.optimizer = keras.optimizers.Adam(learning_rate=self.lr)\n",
        "    self.initializer = tf.keras.initializers.GlorotNormal()\n",
        "    self.batchSize = batchSize\n",
        "    self.number_epochs = adam_iter\n",
        "    self.lowest_iter=0\n",
        "    self.min_loss = 20000\n",
        "    self.params = params\n",
        "    self.X, self.X_pde = X, X.X_pde\n",
        "\n",
        "  def NN(self, inputDim, num_layers, num_neurons=30):\n",
        "    model_ = keras.models.Sequential()\n",
        "    model_.add(keras.layers.Dense(num_neurons, activation='tanh', input_dim=inputDim, kernel_initializer=self.initializer))\n",
        "    for layer in range(num_layers-1):\n",
        "        model_.add(keras.Dense(num_neurons, activation='tanh', kernel_initializer=self.initializer))\n",
        "    model_.add(keras.layers.Dense(1, kernel_initializer=self.initializer))\n",
        "    return model_\n",
        "\n",
        "  def get_value_pde(self, value_function_e, value_function_h, X_pde, idx, false_transient, agent_type):\n",
        "    z,t = tf.convert_to_tensor(X_pde[idx, 0:1]), tf.convert_to_tensor(X_pde[idx, 1:2])\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "      tape.watch(z)\n",
        "      tape.watch(t)\n",
        "      with tf.GradientTape(persistent=True) as tape2:\n",
        "        tape2.watch(z)\n",
        "        if agent_type=='households':\n",
        "          u= value_function_h(tf.concat([z,t], axis=1))\n",
        "        elif agent_type=='experts': u= value_function_e(tf.concat([z,t], axis=1))\n",
        "      u_z = tape.gradient(u, z, unconnected_gradients=tf.UnconnectedGradients.NONE)\n",
        "      u_t = tape.gradient(u, t, unconnected_gradients=tf.UnconnectedGradients.NONE)\n",
        "    u_zz = tape.gradient(u_z, z, unconnected_gradients=tf.UnconnectedGradients.NONE)\n",
        "\n",
        "    if agent_type == 'experts':\n",
        "      advection_z = tf.convert_to_tensor(self.advection_z_e.transpose().reshape(-1,1)[idx])\n",
        "      linearTerm = tf.convert_to_tensor(self.linearTermE.transpose().reshape(-1,1)[idx])\n",
        "    elif agent_type== 'households':\n",
        "      advection_z = tf.convert_to_tensor(self.advection_z_h.transpose().reshape(-1,1)[idx])\n",
        "      linearTerm = tf.convert_to_tensor(self.linearTermH.transpose().reshape(-1,1)[idx])\n",
        "\n",
        "    diffusion_z = tf.convert_to_tensor(self.diffusion_z.transpose().reshape(-1,1)[idx])\n",
        "\n",
        "    u_pde = u_t + advection_z*u_z + diffusion*u_zz - linearTerm*u\n",
        "    return u_pde\n",
        "\n",
        "  def PDESolver(self, value_function_e, value_function_h, j0_e, j0_h, X, X_pde, idx, idx_crisis):\n",
        "    fpde_e = self.get_value_pde(value_function_e, value_function_h, X_pde, idx, True, 'experts')\n",
        "    jE = value_function_e(tf.concat([X[:, 0:1], X[:, 1:2]], axis=1))\n",
        "    fpde_h = self.get_value_pde(value_function_e, value_function_h, X_pde, idx, True, 'households')\n",
        "    jH = value_function_h(tf.concat([X[:, 0:1], X[:, 1:2]], axis=1))\n",
        "\n",
        "    #experts\n",
        "    loss_1_1 = fpde_e\n",
        "    loss_1 = tf.reduce_mean(tf.square(loss_1_1))\n",
        "    loss_2 = tf.reduce_mean(tf.square(jE-j0_e))\n",
        "\n",
        "    #households\n",
        "    loss_3 = tf.reduce_mean(tf.square(jH-j0_h))\n",
        "    loss_4 = tf.reduce_mean(tf.square(fpde_h))\n",
        "\n",
        "    loss = loss_1 + loss_2 + loss_3 + loss_4\n",
        "    return loss, fpde_e\n",
        "\n",
        "  def loss_function(self, batchSize):\n",
        "    idx = np.random.choice(self.X.shape[0], batchSize, replace=True)\n",
        "    loss_total, fpde = self.PDESolver(self.value_function_e, self.value_function_h, self.J0_e, self.J0_h, self.X, self.X_pde, idx, idx_crisis)\n",
        "    return loss_total, fpde\n",
        "\n",
        "  @tf.function\n",
        "  def training_step(self):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "      loss_total, fpde = self.loss_function(self.BatchSize)\n",
        "    grads_value_e = tape.gradient(loss_total, self.theta_valueFunction_e)\n",
        "    grads_value_h = tape.gradient(loss_total, self.theta_valueFunction_h)\n",
        "    self.optimizer.apply_gradients(zip(grads_value_e, self.theta_valueFunction_e))\n",
        "    self.optimizer.apply_gradients(zip(grads_value_h, self.theta_valueFunction_h))\n",
        "    return loss_total, fpde\n",
        "\n",
        "  def train(self):\n",
        "    if os.path.isfile('./save/value_function_experts.h5'):\n",
        "      self.value_function_e = load_model('./save/value_function_experts.h5')\n",
        "    else:\n",
        "      self.value_function_e = self.NN(2, self.params['num_layers'])\n",
        "\n",
        "    if os.path.isfile('./save/value_function_households.h5'):\n",
        "      self.value_function_h = load_model('./save/value_function_experts.h5')\n",
        "    else:\n",
        "      self.value_function_h = self.NN(2, self.params['num_layers'])\n",
        "\n",
        "    self.theta_valueFunction_e = self.value_function_e.trainable_variables\n",
        "    self.theta_valueFunction_h = self.value_function_h.trainable_variables\n",
        "\n",
        "    self.LVF = []\n",
        "    min_loss = float('inf')\n",
        "\n",
        "    start_time = time.time()\n",
        "    for epoch in range(self.number_epochs+1):\n",
        "      loss_total, fpde = self.training_step()\n",
        "      if (loss_total<min_loss):\n",
        "        self.lowest_iter=epoch\n",
        "        min_loss = loss_total\n",
        "        self.best_valueFunction_e.setweights(self.value_function_e.getweights())\n",
        "        self.best_valueFunction_h.setweights(self.value_function_h.getweights())\n",
        "        elapsed_time = time.time()-start_time\n",
        "      if epoch%1000==0:\n",
        "        print('IT: %d, Loss: %.3e, Time: %.2f'%(epoch, min_loss.numpy(), elapsed_time))\n",
        "      self.LVF.append(loss_total.numpy())\n",
        "    self.value_function_e.setweights(self.best_valueFunction_e.getweights())\n",
        "    self.value_function_h.setweights(self.best_valueFunction_h.getweights())\n",
        "    self.fpde = fpde\n",
        "\n",
        "  def predict(self, x_star):\n",
        "    je_new = self.value_function_e(tf.concat([x_star[:, 0:1], x_star[:,1:2]], axis=1))\n",
        "    jh_new = self.value_function_h(tf.concat([x_star[:, 0:1], x_star[:,1:2]], axis=1))\n",
        "    return je_new.numpy(), jh_new.numpy()\n",
        "\n",
        "class model_nnpde_B1():\n",
        "  def __init__(self, params) -> None:\n",
        "    self.params = params\n",
        "\n",
        "    #algorithm parameters\n",
        "    self.convergenceCriterion = 1e-5;\n",
        "    self.dt = 2;\n",
        "    self.converged = 'False'\n",
        "    self.Iter=0\n",
        "\n",
        "    #grid parameters\n",
        "    self.Nf = 1\n",
        "    self.Nz = 1000;\n",
        "    zMin = 0.001;\n",
        "    zMax = 0.999;\n",
        "\n",
        "    #grid parameters\n",
        "    self.Nz = 1000;\n",
        "    zMin = 0.001;\n",
        "    zMax = 0.999\n",
        "\n",
        "    self.z = np.linspace(zMin, zMax, self.Nz);\n",
        "    self.z_mat = np.tile(self.z, (1,1)).transpose()\n",
        "    self.dz = self.z_mat[1:self.Nz] - self.z_mat[0:self.Nz-1];\n",
        "    self.dz2 = self.dz[0:self.Nz-2]**2\n",
        "    self.dz_mat = np.tile(self.dz, (self.Nf,1))\n",
        "\n",
        "    self.Je = np.ones([self.Nz])\n",
        "    self.Jh = np.ones([self.Nz])\n",
        "    self.q = np.ones([self.Nz, 1]);\n",
        "    self.qz = np.array(np.tile(0, (self.Nz, self.Nf)), dtype=np.float64);\n",
        "    self.qzz = np.array(np.tile(0, (self.Nz, self.Nf)), dtype=np.float64);\n",
        "\n",
        "    #allocate memory for other variables\n",
        "    self.psi = np.full([self.Nz,1], np.NaN)\n",
        "    self.chi = np.full([self.Nz,1], np.NaN)\n",
        "    self.ssq = np.full([self.Nz,1], np.NaN)\n",
        "    self.iota = np.full([self.Nz,1], np.NaN)\n",
        "    self.dq = np.full([self.Nz,1], np.NaN)\n",
        "    self.amax = np.float('Inf')\n",
        "    self.amax_vec = []\n",
        "\n",
        "    #setup grid for pde\n",
        "    self.X = np.vstack((self.z, np.full(self.z.shape[0], self.dt))).transpose().astype(np.float64)\n",
        "    self.X_pde = np.vstack((self.z, np.random.uniform(0, self.dt, self.z.shape[0]))).transpose().astype(np.float64)\n",
        "    self.x_star = np.vstack((self.z, np.full(self.z.shape[0], 0))).transpose()\n",
        "\n",
        "  def equations_region1(self, q_p, Psi_p, sig_ka_p, zi):\n",
        "    '''\n",
        "    Solves for the equilibrium policy in the crisis region\n",
        "    Input: old values of capital price(q_p), capital share(Psi_p), return volatility(sig_ka_p), grid_point(zi)\n",
        "    Output: new values from Newton-Rhapson method\n",
        "    '''\n",
        "    dz = self.z[1:self.Nz] - self.z[0:self.Nz-1];\n",
        "    i_p = (q_p-1)/self.params['kappa']\n",
        "    eq1 = (self.params['aE']-self.params['aH'])/q_p- self.params['alpha']*(self.dLogJh[zi]*(1-self.params['gammaH'])-self.dLogJe[zi]*(1-self.params['gamma']))\n",
        "    eq2 = (self.params['rhoE']*self.z[zi] + self.params['rhoH']*(1-self.z[zi-1]))*q_p - Psi_p *(self.params['aE'] -i_p)-\n",
        "    eq3 = sig_ka_p*(1-((q_p-self.q[zi-1][0])/(dz[zi-1]*q_p)*self.z[zi-1]*(self.params['alpha']*Psi_p/self.z[zi]-1)))-\n",
        "    ER = np.array([eq1, eq2, eq3])\n",
        "    QN[0,:] = np.array([-self.params])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    pass"
      ]
    }
  ]
}